{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOxN_NIa62pA",
        "outputId": "7d242ad3-0aff-454a-f29b-3a24ed9f75f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8292, 904)\n",
            "   genes  GSM742944  GSM2326089  GSM1807974  GSM1807990  GSM2055788  \\\n",
            "0   A1BG          0          92       11663        2089       18808   \n",
            "1   A1CF          0          17        5738         490       14035   \n",
            "2    A2M       6362         304       39269        8299       20260   \n",
            "3  A2ML1          0          22          11           2          39   \n",
            "4  A2MP1          0           3         167           7          44   \n",
            "\n",
            "   GSM2142335  GSM1807979  GSM1695909  GSM1554468  ...  GSM2653842  \\\n",
            "0         183        5123       79640        1595  ...        30.0   \n",
            "1           5        7127       10168         241  ...         9.0   \n",
            "2          97       27210       63297        5817  ...         8.0   \n",
            "3           8           4           9           5  ...         4.0   \n",
            "4          15          16          61           2  ...         0.0   \n",
            "\n",
            "   GSM2653843  GSM2653844  GSM2653845  GSM2653846  GSM2653847  GSM2653849  \\\n",
            "0        22.0        17.0        49.0       394.0        12.0         8.0   \n",
            "1         4.0        15.0        19.0       105.0         5.0         8.0   \n",
            "2         6.0         2.0         0.0       374.0         0.0         4.0   \n",
            "3         5.0         1.0         4.0         1.0         6.0         3.0   \n",
            "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
            "\n",
            "   GSM2653850  GSM2653851  GSM2653853  \n",
            "0         6.0        10.0         8.0  \n",
            "1         4.0         2.0        24.0  \n",
            "2         1.0         3.0         1.0  \n",
            "3         3.0         3.0         1.0  \n",
            "4         0.0         0.0         0.0  \n",
            "\n",
            "[5 rows x 904 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8292 entries, 0 to 8291\n",
            "Columns: 904 entries, genes to GSM2653853\n",
            "dtypes: float64(83), int64(820), object(1)\n",
            "memory usage: 57.2+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/human_liver.tsv\", sep=\"\\t\")\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Select only the numeric columns for normalization\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "df_normalized = df[numeric_cols].apply(lambda x: np.log2(x+1))"
      ],
      "metadata": {
        "id": "65VlaK3V8V7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ead_analysis.py\n",
        "# PCA + clustering + heatmap for preprocessed RNA-seq (TSV)\n",
        "# Usage: put your preprocessed TSV in the same folder and name it \"data_preprocessed.tsv\"\n",
        "# or change the FILENAME variable below.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ---------- SETTINGS ----------\n",
        "FILENAME = \"/content/human_liver.tsv\"   # change if needed\n",
        "INDEX_COL = 0                        # row names (genes) are in first column\n",
        "N_PCS = 10\n",
        "N_TOP_VAR_GENES = 500                # for heatmap\n",
        "K_CLUSTERS = 4                       # initial number of clusters to try\n",
        "RANDOM_STATE = 42\n",
        "OUTPUT_DIR = \"eda_outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- LOAD ----------\n",
        "df = pd.read_csv(FILENAME, sep=\"\\t\", index_col=INDEX_COL)\n",
        "# If samples are rows and genes are columns, transpose so that rows=samples, cols=genes\n",
        "if df.shape[0] > df.shape[1]:\n",
        "    # Heuristic: if more rows than columns, we likely have samples in columns -> transpose\n",
        "    df = df.T\n",
        "\n",
        "# df now: rows = samples, columns = genes\n",
        "print(\"Data shape (samples x genes):\", df.shape)\n",
        "\n",
        "# ---------- OPTIONAL: ensure numeric ----------\n",
        "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "df = df.dropna(axis=0, how=\"any\")   # drop samples with NaNs\n",
        "df = df.loc[:, df.var(axis=0) > 0]  # drop constant genes\n",
        "\n",
        "# ---------- SCALE ----------\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "X = scaler.fit_transform(df.values)   # shape: (n_samples, n_genes)\n",
        "\n",
        "# ---------- PCA ----------\n",
        "pca = PCA(n_components=min(N_PCS, X.shape[1]), random_state=RANDOM_STATE)\n",
        "X_pca = pca.fit_transform(X)\n",
        "explained = pca.explained_variance_ratio_\n",
        "\n",
        "# Save explained variance ratio\n",
        "pd.DataFrame({\n",
        "    \"PC\": [f\"PC{i+1}\" for i in range(len(explained))],\n",
        "    \"ExplainedVariance\": explained\n",
        "}).to_csv(os.path.join(OUTPUT_DIR, \"pca_explained_variance.csv\"), index=False)\n",
        "\n",
        "# PCA scatter (PC1 vs PC2)\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1], s=40)\n",
        "for i, sample in enumerate(df.index):\n",
        "    plt.text(X_pca[i,0], X_pca[i,1], sample, fontsize=6, alpha=0.75)\n",
        "plt.xlabel(f\"PC1 ({explained[0]*100:.1f}%)\")\n",
        "plt.ylabel(f\"PC2 ({explained[1]*100:.1f}%)\")\n",
        "plt.title(\"PCA: PC1 vs PC2\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"pca_pc1_pc2.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Scree plot\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(np.arange(1, len(explained)+1), np.cumsum(explained), marker='o')\n",
        "plt.xlabel(\"Number of PCs\")\n",
        "plt.ylabel(\"Cumulative explained variance\")\n",
        "plt.title(\"PCA: Cumulative explained variance\")\n",
        "plt.grid(True, ls='--', alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"pca_cumulative_variance.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ---------- KMeans clustering (on PCA-reduced data) ----------\n",
        "k = K_CLUSTERS\n",
        "kmeans = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=50)\n",
        "# use first N_PCS components (or all computed)\n",
        "pc_for_clustering = min(N_PCS, X_pca.shape[1])\n",
        "labels = kmeans.fit_predict(X_pca[:, :pc_for_clustering])\n",
        "sil = silhouette_score(X_pca[:, :pc_for_clustering], labels)\n",
        "print(f\"KMeans (k={k}) silhouette score: {sil:.4f}\")\n",
        "pd.DataFrame({\"sample\": df.index, \"kmeans_label\": labels}).to_csv(\n",
        "    os.path.join(OUTPUT_DIR, \"kmeans_labels.csv\"), index=False)\n",
        "\n",
        "# PCA scatter colored by cluster\n",
        "plt.figure(figsize=(8,6))\n",
        "palette = sns.color_palette(\"tab10\", n_colors=k)\n",
        "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=labels, palette=palette, s=50, legend='full')\n",
        "plt.xlabel(f\"PC1 ({explained[0]*100:.1f}%)\")\n",
        "plt.ylabel(f\"PC2 ({explained[1]*100:.1f}%)\")\n",
        "plt.title(f\"PCA (PC1 vs PC2) colored by KMeans (k={k})\")\n",
        "plt.legend(title=\"cluster\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, f\"pca_kmeans_k{k}.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ---------- Hierarchical clustering of samples (dendrogram) ----------\n",
        "linked = linkage(X, method='ward')  # use scaled full data (or PCA data if desired)\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(linked, labels=df.index, leaf_rotation=90, leaf_font_size=6, color_threshold=None)\n",
        "plt.title(\"Hierarchical clustering dendrogram (samples)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"dendrogram_samples.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ---------- Heatmap of top variable genes ----------\n",
        "# find top variable genes by variance across samples\n",
        "gene_variances = df.var(axis=0).sort_values(ascending=False)\n",
        "top_genes = gene_variances.index[:min(N_TOP_VAR_GENES, len(gene_variances))]\n",
        "df_top = df.loc[:, top_genes]\n",
        "\n",
        "# Optionally z-score genes (rows: samples, cols: genes) -> we want to show relative expression\n",
        "df_top_z = df_top.apply(lambda x: (x - x.mean()) / x.std(ddof=0), axis=0)\n",
        "\n",
        "# Create clustermap (samples clustered by rows, genes by columns)\n",
        "# seaborn clustermap will cluster rows and cols by default\n",
        "cg = sns.clustermap(df_top_z,\n",
        "                    method='ward',\n",
        "                    metric='euclidean',\n",
        "                    figsize=(12, 10),\n",
        "                    yticklabels=True,\n",
        "                    xticklabels=False,\n",
        "                    cmap=\"vlag\",\n",
        "                    standard_scale=None)\n",
        "plt.title(\"Clustermap (top variable genes)\", pad=100)\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"clustermap_top_genes.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Save the subset used for heatmap as CSV\n",
        "df_top.to_csv(os.path.join(OUTPUT_DIR, \"top_variable_genes.tsv\"), sep=\"\\t\")\n",
        "\n",
        "# ---------- Optional: Save PCA components and transformed matrix ----------\n",
        "pd.DataFrame(X_pca, index=df.index, columns=[f\"PC{i+1}\" for i in range(X_pca.shape[1])]) \\\n",
        "    .to_csv(os.path.join(OUTPUT_DIR, \"samples_pca_coordinates.csv\"))\n",
        "\n",
        "pd.DataFrame(pca.components_, index=[f\"PC{i+1}\" for i in range(pca.components_.shape[0])],\n",
        "             columns=df.columns).to_csv(os.path.join(OUTPUT_DIR, \"pca_components.csv\"))\n",
        "\n",
        "# ---------- PRINT SUMMARY ----------\n",
        "print(\"EDA outputs saved to:\", OUTPUT_DIR)\n",
        "print(\"Files created:\")\n",
        "for f in sorted(os.listdir(OUTPUT_DIR)):\n",
        "    print(\" -\", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm4APm998ltS",
        "outputId": "f70c3f6d-3f79-482d-e61e-9575bcc28c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape (samples x genes): (903, 35238)\n",
            "KMeans (k=4) silhouette score: 0.6285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.12/dist-packages/seaborn/matrix.py:560: UserWarning: Clustering large matrix with scipy. Installing `fastcluster` may give better performance.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDA outputs saved to: eda_outputs\n",
            "Files created:\n",
            " - clustermap_top_genes.png\n",
            " - dendrogram_samples.png\n",
            " - kmeans_labels.csv\n",
            " - pca_components.csv\n",
            " - pca_cumulative_variance.png\n",
            " - pca_explained_variance.csv\n",
            " - pca_kmeans_k4.png\n",
            " - pca_pc1_pc2.png\n",
            " - samples_pca_coordinates.csv\n",
            " - top_variable_genes.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b66f2ab9",
        "outputId": "9d2226dd-51d9-436d-cfaa-962280f02942"
      },
      "source": [
        "# Create a dummy metadata file for demonstration purposes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming samples are the columns of your original df before transposing in the DE script\n",
        "sample_names = df.columns.tolist()\n",
        "\n",
        "# Create dummy groups: first half healthy, second half diseased\n",
        "n_samples = len(sample_names)\n",
        "groups = ['Healthy'] * (n_samples // 2) + ['Diseased'] * (n_samples - n_samples // 2)\n",
        "\n",
        "# Shuffle the groups randomly to make it more realistic\n",
        "np.random.seed(42) # for reproducibility\n",
        "np.random.shuffle(groups)\n",
        "\n",
        "metadata_df = pd.DataFrame({'sample': sample_names, 'group': groups})\n",
        "\n",
        "# Save the dummy metadata to metadata.tsv\n",
        "metadata_df.to_csv(\"metadata.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Dummy metadata.tsv created.\")\n",
        "print(metadata_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy metadata.tsv created.\n",
            "       sample     group\n",
            "0   GSM742944   Healthy\n",
            "1  GSM2326089  Diseased\n",
            "2  GSM1807974   Healthy\n",
            "3  GSM1807990   Healthy\n",
            "4  GSM2055788   Healthy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# differential_expression_and_volcano_fixed.py\n",
        "# Improved robust version to avoid KeyError when metadata/sample orientation mismatches.\n",
        "# Usage:\n",
        "# - Put your preprocessed data TSV as \"data_preprocessed.tsv\"\n",
        "#   (can be samples x genes or genes x samples; this script will auto-detect)\n",
        "# - Put a metadata TSV/CSV with columns: sample (matching sample IDs) and group as \"metadata.tsv\"\n",
        "# - Run: python differential_expression_and_volcano_fixed.py\n",
        "#\n",
        "# Output:\n",
        "# - de_outputs/de_results.tsv\n",
        "# - de_outputs/volcano_plot.png\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "FNAME_DATA = \"/content/human_liver.tsv\"\n",
        "FNAME_META = \"metadata.tsv\"        # must contain columns: sample, group\n",
        "OUTPUT_DIR = \"de_outputs\"\n",
        "ALPHA = 0.05\n",
        "FC_VISUAL_THRESHOLD = 1.0\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def load_data(fname):\n",
        "    df = pd.read_csv(fname, sep=\"\\t\", header=0, index_col=0)\n",
        "    return df\n",
        "\n",
        "def load_meta(fname):\n",
        "    # auto-detect separator\n",
        "    meta = pd.read_csv(fname, sep=None, engine='python')\n",
        "    if 'sample' not in meta.columns or 'group' not in meta.columns:\n",
        "        raise ValueError(\"metadata must contain 'sample' and 'group' columns\")\n",
        "    return meta[['sample', 'group']].copy()\n",
        "\n",
        "def align_samples(df, meta):\n",
        "    sample_ids = meta['sample'].astype(str).tolist()\n",
        "    df_index = df.index.astype(str).tolist()\n",
        "    df_columns = df.columns.astype(str).tolist()\n",
        "\n",
        "    # If samples are rows (df.index contains sample ids)\n",
        "    overlap_index = set(df_index).intersection(sample_ids)\n",
        "    overlap_columns = set(df_columns).intersection(sample_ids)\n",
        "\n",
        "    if len(overlap_index) >= max(1, int(0.5 * len(sample_ids))):\n",
        "        # majority of sample ids found in index -> rows are samples\n",
        "        df_samples = df.copy()\n",
        "    elif len(overlap_columns) >= max(1, int(0.5 * len(sample_ids))):\n",
        "        # majority found in columns -> transpose\n",
        "        df_samples = df.T.copy()\n",
        "    else:\n",
        "        # not enough overlap: show helpful diagnostics and try to proceed with intersection if possible\n",
        "        inter = set(sample_ids).intersection(set(df_index)).union(set(sample_ids).intersection(set(df_columns)))\n",
        "        if len(inter) == 0:\n",
        "            raise KeyError(\n",
        "                \"No overlap found between sample IDs in metadata and data file.\\n\"\n",
        "                \"Metadata sample IDs (examples): {}\\n\"\n",
        "                \"Data index examples: {}\\n\"\n",
        "                \"Data column examples: {}\\n\"\n",
        "                \"Make sure the metadata 'sample' values exactly match sample names in the data.\".format(\n",
        "                    sample_ids[:5], df_index[:5], df_columns[:5]\n",
        "                )\n",
        "            )\n",
        "        # proceed using the intersection (partial)\n",
        "        print(f\"Warning: Only {len(inter)} samples overlap between data and metadata. Proceeding with intersection.\")\n",
        "        # prefer rows if intersection with index, else transpose\n",
        "        if len(set(df_index).intersection(inter)) > 0:\n",
        "            df_samples = df.loc[list(set(df_index).intersection(inter))].copy()\n",
        "        else:\n",
        "            df_samples = df.loc[:, list(set(df_columns).intersection(inter))].T.copy()\n",
        "\n",
        "    # ensure sample order matches metadata order (use intersection)\n",
        "    common = [s for s in meta['sample'].astype(str).tolist() if s in df_samples.index.astype(str).tolist()]\n",
        "    if len(common) < 2:\n",
        "        raise ValueError(f\"After alignment, found fewer than 2 samples in common: {len(common)}. Need >=2 per group.\")\n",
        "    df_aligned = df_samples.loc[common].copy()\n",
        "    meta_aligned = meta.set_index(meta['sample'].astype(str)).loc[common].copy()\n",
        "    # reset index types, ensure ordering identical\n",
        "    df_aligned.index = df_aligned.index.astype(str)\n",
        "    meta_aligned.index = meta_aligned.index.astype(str)\n",
        "    assert list(df_aligned.index) == list(meta_aligned.index)\n",
        "    return df_aligned, meta_aligned\n",
        "\n",
        "def differential_expression(df, meta, output_dir):\n",
        "    # df: rows = samples, cols = genes\n",
        "    groups = meta['group'].unique()\n",
        "    if len(groups) != 2:\n",
        "        raise ValueError(f\"This script performs two-group differential expression. Found groups: {list(groups)}\")\n",
        "\n",
        "    g1, g2 = groups[0], groups[1]\n",
        "    ix1 = meta['group'] == g1\n",
        "    ix2 = meta['group'] == g2\n",
        "    n1, n2 = ix1.sum(), ix2.sum()\n",
        "    if n1 < 2 or n2 < 2:\n",
        "        raise ValueError(f\"Need at least 2 samples per group. Found {n1} for {g1} and {n2} for {g2}.\")\n",
        "\n",
        "    X1 = df.loc[ix1.values, :]\n",
        "    X2 = df.loc[ix2.values, :]\n",
        "\n",
        "    # Filter genes with zero variance\n",
        "    var_all = df.var(axis=0)\n",
        "    keep = var_all > 0\n",
        "    if keep.sum() == 0:\n",
        "        raise ValueError(\"All genes have zero variance after filtering.\")\n",
        "    X1 = X1.loc[:, keep]\n",
        "    X2 = X2.loc[:, keep]\n",
        "    genes = X1.columns.values\n",
        "\n",
        "    # Means & log2FC (assumes data normalized/log-transformed already)\n",
        "    mean1 = X1.mean(axis=0)\n",
        "    mean2 = X2.mean(axis=0)\n",
        "    log2fc = mean1 - mean2\n",
        "\n",
        "    # Welch t-test\n",
        "    tstat, pvals = stats.ttest_ind(X1.values, X2.values, axis=0, equal_var=False, nan_policy='omit')\n",
        "    pvals = np.nan_to_num(pvals, nan=1.0)\n",
        "    tstat = np.nan_to_num(tstat, nan=0.0)\n",
        "\n",
        "    reject, pvals_adj, _, _ = multipletests(pvals, alpha=ALPHA, method='fdr_bh')\n",
        "\n",
        "    res = pd.DataFrame({\n",
        "        \"gene\": genes,\n",
        "        f\"mean_{g1}\": mean1.values,\n",
        "        f\"mean_{g2}\": mean2.values,\n",
        "        \"log2FC\": log2fc.values,\n",
        "        \"t_stat\": tstat,\n",
        "        \"pval\": pvals,\n",
        "        \"adj_pval\": pvals_adj,\n",
        "        \"significant\": reject\n",
        "    }).set_index(\"gene\")\n",
        "    res = res.sort_values(\"adj_pval\")\n",
        "    res.to_csv(os.path.join(output_dir, \"de_results.tsv\"), sep=\"\\t\")\n",
        "    return res, (g1, g2)\n",
        "\n",
        "def volcano_plot(res, groups, output_dir):\n",
        "    g1, g2 = groups\n",
        "    res = res.copy()\n",
        "    res['neg_log10_pval'] = -np.log10(res['pval'] + 1e-300)\n",
        "    res['sig'] = res['adj_pval'] <= ALPHA\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.scatterplot(x=res['log2FC'], y=res['neg_log10_pval'],\n",
        "                    hue=res['sig'], palette={False: 'grey', True: 'red'}, legend=False, s=10)\n",
        "\n",
        "    # label top hits\n",
        "    res['score'] = res['neg_log10_pval'] * np.abs(res['log2FC'])\n",
        "    top_hits = res.sort_values('score', ascending=False).head(20)\n",
        "    for gene, row in top_hits.iterrows():\n",
        "        plt.text(row['log2FC'], row['neg_log10_pval'], gene, fontsize=6, alpha=0.85)\n",
        "\n",
        "    plt.axhline(-np.log10(0.05), color='blue', linestyle='--', linewidth=0.7)\n",
        "    plt.axvline(-FC_VISUAL_THRESHOLD, color='green', linestyle='--', linewidth=0.7)\n",
        "    plt.axvline(FC_VISUAL_THRESHOLD, color='green', linestyle='--', linewidth=0.7)\n",
        "    plt.xlabel(f'log2 Fold Change ({g1} vs {g2})')\n",
        "    plt.ylabel('-log10(p-value)')\n",
        "    plt.title(f'Volcano plot: {g1} vs {g2}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, \"volcano_plot.png\"), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        df = load_data(FNAME_DATA)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load data file:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    try:\n",
        "        meta = load_meta(FNAME_META)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load metadata file:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    try:\n",
        "        df_aligned, meta_aligned = align_samples(df, meta)\n",
        "    except Exception as e:\n",
        "        print(\"Sample alignment error:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Save aligned table heads for user's inspection\n",
        "    df_aligned.head(3).to_csv(os.path.join(OUTPUT_DIR, \"data_aligned_head.tsv\"), sep=\"\\t\")\n",
        "    meta_aligned.head(10).to_csv(os.path.join(OUTPUT_DIR, \"meta_aligned_head.tsv\"), sep=\"\\t\")\n",
        "\n",
        "    try:\n",
        "        res, groups = differential_expression(df_aligned, meta_aligned, OUTPUT_DIR)\n",
        "    except Exception as e:\n",
        "        print(\"Differential expression error:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    volcano_plot(res, groups, OUTPUT_DIR)\n",
        "\n",
        "    print(\"DE analysis complete.\")\n",
        "    print(\"Results saved to:\", os.path.join(OUTPUT_DIR, \"de_results.tsv\"))\n",
        "    print(\"Volcano plot saved to:\", os.path.join(OUTPUT_DIR, \"volcano_plot.png\"))\n",
        "    print(\"Aligned data/metadata heads saved to:\", os.path.join(OUTPUT_DIR, \"data_aligned_head.tsv\"),\n",
        "          \"and\", os.path.join(OUTPUT_DIR, \"meta_aligned_head.tsv\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w24nm9UArLW",
        "outputId": "7e3536bc-198a-4ceb-b4a6-a09be275b325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DE analysis complete.\n",
            "Results saved to: de_outputs/de_results.tsv\n",
            "Volcano plot saved to: de_outputs/volcano_plot.png\n",
            "Aligned data/metadata heads saved to: de_outputs/data_aligned_head.tsv and de_outputs/meta_aligned_head.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "res = pd.read_csv(\"de_outputs/de_results.tsv\", sep=\"\\t\", index_col=0)\n",
        "# filter by adjusted p-value and absolute log2FC\n",
        "sig = res[(res['adj_pval'] <= 0.05) & (res['log2FC'].abs() >= 1.0)]\n",
        "print(\"Significant genes:\", sig.shape[0])\n",
        "sig.head()\n",
        "# Save\n",
        "sig.to_csv(\"de_outputs/significant_genes.tsv\", sep=\"\\t\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtrMlA__Bi1_",
        "outputId": "899ab8e0-2874-4e94-917a-7e0caa647265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Significant genes: 0\n"
          ]
        }
      ]
    }
  ]
}